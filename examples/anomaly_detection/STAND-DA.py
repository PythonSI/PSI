r"""
Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation
====================================================================================================================
"""

# Author: Tran Tuan Kiet

from pythonsi import Pipeline, Data
from pythonsi.domain_adaptation import WDGRL
from pythonsi.anomaly_detection import AE
from pythonsi.test_statistics import AD_DA_TestStatistic
import numpy as np
import matplotlib.pyplot as plt
from models.wdgrl import Generator
from models.ae import Autoencoder
from typing import List
import torch

# %%
# Define the pipeline
# -------------------


def STAND_DA(feature_extractor, autoencoder) -> Pipeline:
    xs = Data()

    xt = Data()

    x_tilde = feature_extractor.run(xs=xs, xt=xt)

    anomaly_indices = autoencoder.run(x_tilde)
    return Pipeline(
        inputs=(xs, xt),
        output=anomaly_indices,
        test_statistic=AD_DA_TestStatistic(xs=xs, xt=xt),
    )


my_pipeline = STAND_DA()

# %% Generate Data
# -----------------


def gen_data(mu: float, delta: List[int], n: int, d: int, alpha: float = 0.05):
    mu = np.full((n, d), mu, dtype=np.float64)
    noise = np.random.normal(loc=0, scale=1, size=(n, d))
    X = mu + noise
    labels = np.zeros(n)

    # 5% of the data is abnormal.
    # Anomalies are generated by randomly adding deltas to the data.
    n_anomalies = min(20, int(n * alpha))
    idx = np.random.choice(n, n_anomalies, replace=False)

    if len(delta) == 0:
        return X, labels

    split_points = sorted(
        np.random.choice(range(1, len(idx)), len(delta) - 1, replace=False)
    )
    segments = np.split(idx, split_points)
    for i, segment in enumerate(segments):
        X[segment] = X[segment] + delta[i]
    labels[idx] = 1
    return X, labels, np.identity(n * d)


ns, nt, d = 150, 25, 32

xs, _, sigma_s = gen_data(0, [4], ns, d)
xt, _, sigma_t = gen_data(2, [4], nt, d)

# %%
# Load pretrained models
# -------------------------

feature_extractor = Generator(input_dim=d, hidden_dims=[500, 100])
autoencoder = Autoencoder(
    input_dim=100, encoder_hidden_dims=[16, 8, 4, 2], decoder_hidden_dims=[2, 4, 8, 16]
)

feature_extractor.load_state_dict(torch.load("models/weights/feature_extractor.pth"))
autoencoder.load_state_dict(torch.load("models/weights/autoencoder.pth"))

# %%
# Run the pipeline
# -----------------

anomalies, p_values = my_pipeline(
    inputs=[xs, ys, xt, yt], covariances=[sigma_s, sigma_t]
)

print("Anomalies set: ", anomalies)
print("P-values: ", p_values)

# %%
# Plot the p-values
plt.figure()
plt.bar(range(len(p_values)), p_values)
plt.xlabel("Anomalies index")
plt.ylabel("P-value")
plt.show()
